{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03c99519ca244874993efb9210d46912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dd2964229b64c2a8b9cefb5be1bc19a",
              "IPY_MODEL_3643f2f9b0954dcd91b878c04d218ae9",
              "IPY_MODEL_c188c94ecf8c4f4dab0b1e59367d835b"
            ],
            "layout": "IPY_MODEL_ae771aa02c55435cb809d460afeee892"
          }
        },
        "8dd2964229b64c2a8b9cefb5be1bc19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af220d5b23e74326a988f15569aee4e6",
            "placeholder": "​",
            "style": "IPY_MODEL_499ee477cd8d40088a28b7a8ce336987",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3643f2f9b0954dcd91b878c04d218ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2036c3cec0c94ecab87d739c95443247",
            "max": 50500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_846eaaf28b05441183d1178e22f3ac2a",
            "value": 50500
          }
        },
        "c188c94ecf8c4f4dab0b1e59367d835b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc05d9420884d08b7faf6f6f13a3e86",
            "placeholder": "​",
            "style": "IPY_MODEL_6cf2da20dbdb4dbe83bd60ed910fbfe1",
            "value": " 50.5k/50.5k [00:00&lt;00:00, 1.31MB/s]"
          }
        },
        "ae771aa02c55435cb809d460afeee892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af220d5b23e74326a988f15569aee4e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "499ee477cd8d40088a28b7a8ce336987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2036c3cec0c94ecab87d739c95443247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "846eaaf28b05441183d1178e22f3ac2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccc05d9420884d08b7faf6f6f13a3e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cf2da20dbdb4dbe83bd60ed910fbfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e29aae4257af4373870c96ef4568bd28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b938795b645e489397be1cdbf40f7689",
              "IPY_MODEL_c5e379e8407a4b4b8d75d1dfdec5ac1b",
              "IPY_MODEL_d2a3eca0b89244acb6c73541720c15d9"
            ],
            "layout": "IPY_MODEL_b8fcef4e9d814db0a77e3cd4f71c576d"
          }
        },
        "b938795b645e489397be1cdbf40f7689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90ece6fcac0460c896fe6f0e6c4ef80",
            "placeholder": "​",
            "style": "IPY_MODEL_c9f42ab36f4d43b4a39e5e9b0513bb23",
            "value": "tokenizer.json: 100%"
          }
        },
        "c5e379e8407a4b4b8d75d1dfdec5ac1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3238f6c5f5174302b08022a2eaa68fe6",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_002b08c5a70043889f6eeb3cc8b3bedf",
            "value": 9085657
          }
        },
        "d2a3eca0b89244acb6c73541720c15d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f705bd467e804442a3139873e65848b7",
            "placeholder": "​",
            "style": "IPY_MODEL_bab8034565944253893bafe7388eab8a",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 10.5MB/s]"
          }
        },
        "b8fcef4e9d814db0a77e3cd4f71c576d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90ece6fcac0460c896fe6f0e6c4ef80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9f42ab36f4d43b4a39e5e9b0513bb23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3238f6c5f5174302b08022a2eaa68fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002b08c5a70043889f6eeb3cc8b3bedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f705bd467e804442a3139873e65848b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab8034565944253893bafe7388eab8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7841b39a62dd4f098960a05e31bace47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e731e0bc772488c8ff7fa142e14655e",
              "IPY_MODEL_1e880cb02c7e4d1e938c8f9d1d58b9f3",
              "IPY_MODEL_a985c88f8c0648508b6fa2805042109c"
            ],
            "layout": "IPY_MODEL_18e861d8d05e4505b3dcbef29110626c"
          }
        },
        "3e731e0bc772488c8ff7fa142e14655e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b6831230f484a628affd93c135817f1",
            "placeholder": "​",
            "style": "IPY_MODEL_6ac38152fa1549558bae582c7ac133d1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1e880cb02c7e4d1e938c8f9d1d58b9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c30d18610cf4db8b347aba55de804a1",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c8efc5c895f4fddaea7de1195c4842e",
            "value": 301
          }
        },
        "a985c88f8c0648508b6fa2805042109c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be8431546812454e8bbc53f6efac9165",
            "placeholder": "​",
            "style": "IPY_MODEL_822017913af14fb38e1cf4ad78ee7723",
            "value": " 301/301 [00:00&lt;00:00, 4.79kB/s]"
          }
        },
        "18e861d8d05e4505b3dcbef29110626c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b6831230f484a628affd93c135817f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac38152fa1549558bae582c7ac133d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c30d18610cf4db8b347aba55de804a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c8efc5c895f4fddaea7de1195c4842e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be8431546812454e8bbc53f6efac9165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "822017913af14fb38e1cf4ad78ee7723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b678635f09b49a1a4d858237cd5f329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c012590995d408988376b47e2eee60b",
              "IPY_MODEL_1c8b6ca489204a4ab9ff2753c551e02d",
              "IPY_MODEL_bea74da317c749498b9cc8e99bb24743"
            ],
            "layout": "IPY_MODEL_8aa962ea5ae8471bb110d7551410c16e"
          }
        },
        "5c012590995d408988376b47e2eee60b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_672e01bf8c104f598b508898aaffde4e",
            "placeholder": "​",
            "style": "IPY_MODEL_571a1e0f9e8d432e9aca5c6e267b287b",
            "value": "config.json: 100%"
          }
        },
        "1c8b6ca489204a4ab9ff2753c551e02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bbbbc96e9e6499eb4a9d867f0b8fa38",
            "max": 843,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_497d2261d4c64e169c78fd432adf6b65",
            "value": 843
          }
        },
        "bea74da317c749498b9cc8e99bb24743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d31bc1fabad443cb03602b2ac43f426",
            "placeholder": "​",
            "style": "IPY_MODEL_38f3d1911a3e4e4f83d7781421371ae6",
            "value": " 843/843 [00:00&lt;00:00, 8.74kB/s]"
          }
        },
        "8aa962ea5ae8471bb110d7551410c16e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "672e01bf8c104f598b508898aaffde4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571a1e0f9e8d432e9aca5c6e267b287b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bbbbc96e9e6499eb4a9d867f0b8fa38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497d2261d4c64e169c78fd432adf6b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d31bc1fabad443cb03602b2ac43f426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38f3d1911a3e4e4f83d7781421371ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11cd995016b949f7a2fe9e3f9ed75215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92fc32c11185428b9281a9d073ba85fa",
              "IPY_MODEL_f19e23d121ec406685ab45a3a4a79b60",
              "IPY_MODEL_0ff9dc97e4604b17b39c4c2afe2de8a0"
            ],
            "layout": "IPY_MODEL_2c435e2a03e44e7d941cef5bde9223d3"
          }
        },
        "92fc32c11185428b9281a9d073ba85fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44d74f58457d40e489bc242835206d70",
            "placeholder": "​",
            "style": "IPY_MODEL_c9a6d4fe8a454459805c4cd680507b7e",
            "value": "model.safetensors: 100%"
          }
        },
        "f19e23d121ec406685ab45a3a4a79b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fcf210d8831437f8b6786d8df9f6641",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_791e1bb6d4cf42ee9ce8adac89099d4c",
            "value": 2471645608
          }
        },
        "0ff9dc97e4604b17b39c4c2afe2de8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c318ced6954c4d09b8e7c88dde7cda9e",
            "placeholder": "​",
            "style": "IPY_MODEL_1b18a8d0cbf141788dcddde8acddc255",
            "value": " 2.47G/2.47G [00:36&lt;00:00, 95.8MB/s]"
          }
        },
        "2c435e2a03e44e7d941cef5bde9223d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d74f58457d40e489bc242835206d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a6d4fe8a454459805c4cd680507b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fcf210d8831437f8b6786d8df9f6641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791e1bb6d4cf42ee9ce8adac89099d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c318ced6954c4d09b8e7c88dde7cda9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b18a8d0cbf141788dcddde8acddc255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "293e526cea6548da871c02f9c62862d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b95415e1f3104b60a6ad7084acfb2772",
              "IPY_MODEL_a222615d716040e9ba5261625e4e94c2",
              "IPY_MODEL_e3478afa885c4a4d9803270c8f27e872"
            ],
            "layout": "IPY_MODEL_1b79a1c6bd34403893721daef79b749e"
          }
        },
        "b95415e1f3104b60a6ad7084acfb2772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_612acf35920f4ca1b5e10ed19c8fe139",
            "placeholder": "​",
            "style": "IPY_MODEL_185d04066e3b4a60a6713f5d24b72192",
            "value": "generation_config.json: 100%"
          }
        },
        "a222615d716040e9ba5261625e4e94c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5195070f9653431cba1694a97e58cc55",
            "max": 185,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8128bc97a509460a9fde2624378a0ece",
            "value": 185
          }
        },
        "e3478afa885c4a4d9803270c8f27e872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a69022f15d44084a6f59dd9eff5543a",
            "placeholder": "​",
            "style": "IPY_MODEL_8aca0606eb41437cb53624d8ad39e7e4",
            "value": " 185/185 [00:00&lt;00:00, 15.3kB/s]"
          }
        },
        "1b79a1c6bd34403893721daef79b749e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "612acf35920f4ca1b5e10ed19c8fe139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185d04066e3b4a60a6713f5d24b72192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5195070f9653431cba1694a97e58cc55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8128bc97a509460a9fde2624378a0ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a69022f15d44084a6f59dd9eff5543a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aca0606eb41437cb53624d8ad39e7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyMuPDF sentence-transformers chromadb --quiet\n",
        "from huggingface_hub import login\n",
        "login(token=\"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\")\n",
        "\n",
        "import requests\n",
        "import fitz\n",
        "import os\n",
        "import chromadb\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  print(\"GPU is available\")\n",
        "elif torch.backends.mps.is_available():\n",
        "  device=torch.device(\"mps\")\n",
        "  print(\"MPS is available\")\n",
        "else:\n",
        "  device=torch.device(\"cpu\")\n",
        "  print(\"CUDA is not available\")\n",
        "\n",
        "chroma_client=chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "collection=chroma_client.get_or_create_collection(name=\"arxiv_papers\")\n",
        "\n",
        "embedding_model=SentenceTransformer(\"BAAI/bge-m3\").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6iJTMjogKJE",
        "outputId": "dff94857-6e52-433f-b830-c39f0f242c72"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llama_model_name=\"meta-llama/Llama-3.2-1B\"\n",
        "tokenizer=AutoTokenizer.from_pretrained(llama_model_name)\n",
        "model=AutoModelForCausalLM.from_pretrained(llama_model_name).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "03c99519ca244874993efb9210d46912",
            "8dd2964229b64c2a8b9cefb5be1bc19a",
            "3643f2f9b0954dcd91b878c04d218ae9",
            "c188c94ecf8c4f4dab0b1e59367d835b",
            "ae771aa02c55435cb809d460afeee892",
            "af220d5b23e74326a988f15569aee4e6",
            "499ee477cd8d40088a28b7a8ce336987",
            "2036c3cec0c94ecab87d739c95443247",
            "846eaaf28b05441183d1178e22f3ac2a",
            "ccc05d9420884d08b7faf6f6f13a3e86",
            "6cf2da20dbdb4dbe83bd60ed910fbfe1",
            "e29aae4257af4373870c96ef4568bd28",
            "b938795b645e489397be1cdbf40f7689",
            "c5e379e8407a4b4b8d75d1dfdec5ac1b",
            "d2a3eca0b89244acb6c73541720c15d9",
            "b8fcef4e9d814db0a77e3cd4f71c576d",
            "c90ece6fcac0460c896fe6f0e6c4ef80",
            "c9f42ab36f4d43b4a39e5e9b0513bb23",
            "3238f6c5f5174302b08022a2eaa68fe6",
            "002b08c5a70043889f6eeb3cc8b3bedf",
            "f705bd467e804442a3139873e65848b7",
            "bab8034565944253893bafe7388eab8a",
            "7841b39a62dd4f098960a05e31bace47",
            "3e731e0bc772488c8ff7fa142e14655e",
            "1e880cb02c7e4d1e938c8f9d1d58b9f3",
            "a985c88f8c0648508b6fa2805042109c",
            "18e861d8d05e4505b3dcbef29110626c",
            "0b6831230f484a628affd93c135817f1",
            "6ac38152fa1549558bae582c7ac133d1",
            "1c30d18610cf4db8b347aba55de804a1",
            "0c8efc5c895f4fddaea7de1195c4842e",
            "be8431546812454e8bbc53f6efac9165",
            "822017913af14fb38e1cf4ad78ee7723",
            "4b678635f09b49a1a4d858237cd5f329",
            "5c012590995d408988376b47e2eee60b",
            "1c8b6ca489204a4ab9ff2753c551e02d",
            "bea74da317c749498b9cc8e99bb24743",
            "8aa962ea5ae8471bb110d7551410c16e",
            "672e01bf8c104f598b508898aaffde4e",
            "571a1e0f9e8d432e9aca5c6e267b287b",
            "7bbbbc96e9e6499eb4a9d867f0b8fa38",
            "497d2261d4c64e169c78fd432adf6b65",
            "2d31bc1fabad443cb03602b2ac43f426",
            "38f3d1911a3e4e4f83d7781421371ae6",
            "11cd995016b949f7a2fe9e3f9ed75215",
            "92fc32c11185428b9281a9d073ba85fa",
            "f19e23d121ec406685ab45a3a4a79b60",
            "0ff9dc97e4604b17b39c4c2afe2de8a0",
            "2c435e2a03e44e7d941cef5bde9223d3",
            "44d74f58457d40e489bc242835206d70",
            "c9a6d4fe8a454459805c4cd680507b7e",
            "2fcf210d8831437f8b6786d8df9f6641",
            "791e1bb6d4cf42ee9ce8adac89099d4c",
            "c318ced6954c4d09b8e7c88dde7cda9e",
            "1b18a8d0cbf141788dcddde8acddc255",
            "293e526cea6548da871c02f9c62862d2",
            "b95415e1f3104b60a6ad7084acfb2772",
            "a222615d716040e9ba5261625e4e94c2",
            "e3478afa885c4a4d9803270c8f27e872",
            "1b79a1c6bd34403893721daef79b749e",
            "612acf35920f4ca1b5e10ed19c8fe139",
            "185d04066e3b4a60a6713f5d24b72192",
            "5195070f9653431cba1694a97e58cc55",
            "8128bc97a509460a9fde2624378a0ece",
            "2a69022f15d44084a6f59dd9eff5543a",
            "8aca0606eb41437cb53624d8ad39e7e4"
          ]
        },
        "id": "iJMuOkKHghHG",
        "outputId": "b1753e74-44cb-4158-85d3-eb30c8fbc2a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03c99519ca244874993efb9210d46912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e29aae4257af4373870c96ef4568bd28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7841b39a62dd4f098960a05e31bace47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b678635f09b49a1a4d858237cd5f329"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11cd995016b949f7a2fe9e3f9ed75215"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "293e526cea6548da871c02f9c62862d2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ccg1ocH-cPdF"
      },
      "outputs": [],
      "source": [
        "def extract_arxiv_id(abstract_url):\n",
        "    return abstract_url.split(\"/\")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_pdf(arxiv_id):\n",
        "  pdf_url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
        "  response = requests.get(pdf_url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    pdf_path = f\"{arxiv_id}.pdf\"\n",
        "    with open(pdf_path,\"wb\") as f:\n",
        "      f.write(response.content)\n",
        "    return pdf_path\n",
        "  else:\n",
        "    raise Exception(f\"Failed to download PDF: {pdf_url}\")"
      ],
      "metadata": {
        "id": "TX2wAx9zca73"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "  doc = fitz.open(pdf_path)\n",
        "  text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
        "  doc.close()\n",
        "  return text"
      ],
      "metadata": {
        "id": "KEqWho67dKma"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text,chunk_size=512):\n",
        "  words = text.split()\n",
        "  return [\" \".join(words[i:i+chunk_size]) for i in range(0,len(words),chunk_size)]"
      ],
      "metadata": {
        "id": "ME1mqlwCdYlz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def store_in_chroma(arxiv_id,text):\n",
        "  text_chunks = chunk_text(text)\n",
        "  print(text_chunks)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    embeddings = embedding_model.encode(text_chunks,normalize_embeddings=True, convert_to_tensor = True).cpu().tolist()\n",
        "\n",
        "  for i,chunk in enumerate(text_chunks):\n",
        "    collection.add(\n",
        "        ids = [f\"{arxiv_id}-{i}\"],\n",
        "        documents = [chunk],\n",
        "        metadatas = [{\"source\": f\"https://arxiv.org/{arxiv_id}\", \"chunk_id\":i}],\n",
        "        embeddings = [embeddings[i]]\n",
        "    )"
      ],
      "metadata": {
        "id": "VZ8YGynLeOHc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_arxiv_paper(abstract_url):\n",
        "  arxiv_id = extract_arxiv_id(abstract_url)\n",
        "  print(f\"Processing arxiv paper: {arxiv_id}\")\n",
        "  pdf_path = download_pdf(arxiv_id)\n",
        "  text = extract_text_from_pdf(pdf_path)\n",
        "  print(f\"Extracted {len(text)} characters of text\")\n",
        "  store_in_chroma(arxiv_id,text)\n",
        "  os.remove(pdf_path)\n",
        "  print(\"Processing complete\")"
      ],
      "metadata": {
        "id": "8yDbpC8GfqKy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_chunks(query,top_k = 5):\n",
        "  query_embedding = embedding_model.encode(query,normalize_embeddings=True).tolist()\n",
        "  results = collection.query(\n",
        "      query_embeddings = [query_embedding],\n",
        "      n_results = top_k\n",
        "  )\n",
        "\n",
        "  if results[\"documents\"]:\n",
        "    return results[\"documents\"][0]\n",
        "  else:\n",
        "    return []\n"
      ],
      "metadata": {
        "id": "9ebGk2RChtN5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(query, max_new_tokens = 3000,top_k=3):\n",
        "  retrieved_texts = retrieve_relevant_chunks(query,top_k=top_k)\n",
        "  if not retrieved_texts:\n",
        "    return \"No relevant information found in the database.\"\n",
        "  context = \"\\n\\n\".join(retrieved_texts)[:3000]\n",
        "  prompt = f\"Context:\\n{context}\\n\\nQuestion:{query}\\nAnswer:\"\n",
        "  inputs = tokenizer(prompt, return_tensors = \"pt\", truncation = True).to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs = model.generate(**inputs, max_new_tokens = max_new_tokens)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
        "  return answer"
      ],
      "metadata": {
        "id": "VoqbeugSihzE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_arxiv_paper(\"https://arxiv.org/abs/2503.01751\")\n",
        "print(generate_response(\"What does the conclusion of this paper say?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac_XfWiRkxYD",
        "outputId": "af7f1f09-c026-441a-aabe-b105868e0a0c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing arxiv paper: 2503.01751\n",
            "Extracted 51153 characters of text\n",
            "['SAKE: Steering Activations for Knowledge Editing Marco Scialanga*,1,2, Thibault Laugel*,1,3, Vincent Grari1,3, Marcin Detyniecki1,3,4 1AXA, Paris, France, 2EPFL, Lausanne, Switzerland, 3TRAIL, LIP6, Sorbonne Université, Paris, France 4Polish Academy of Science, IBS PAN, Warsaw, Poland *Equal contribution Correspondence: marco.scialanga@epfl.ch, thibault.laugel@axa.com Abstract As Large Langue Models have been shown to memorize real-world facts, the need to update this knowledge in a controlled and efficient manner arises. Designed with these constraints in mind, Knowledge Editing (KE) approaches propose to alter specific facts in pretrained mod- els. However, they have been shown to suffer from several limitations, including their lack of contextual robustness and their failure to gener- alize to logical implications related to the fact. To overcome these issues, we propose SAKE, a steering activation method that models a fact to be edited as a distribution rather than a sin- gle prompt. Leveraging Optimal Transport, SAKE alters the LLM behavior over a whole fact-related distribution, defined as paraphrases and logical implications. Several numerical ex- periments demonstrate the effectiveness of this method: SAKE is thus able to perform more robust edits than its existing counterparts. 1 Introduction It is well known that Large Language Models (LLMs) can store numerous facts in their pa- rameters and recall them when prompted accord- ingly (Petroni et al., 2019; Jiang et al., 2020; Chang et al., 2024; Wang et al., 2024b). As they are gen- erally used in a dynamic environment, the need of keeping these models up to date with new informa- tion and erasing obsolete facts from their memory emerges. Traditionally, this has been accomplished with parameter fine-tuning (Zhu et al., 2020), opti- mizing the pre-trained weights of LLMs with new data. Yet, despite efforts to make them more effi- cient (Hu et al., 2021; Rafailov et al., 2024), the high computational cost and significant risk of over- fitting make fine-tuning techniques being generally viewed as being suboptimal for the task of facts editing (Meng et al., 2022a). Consequently, several recent works have focused on Knowledge Editing (KE), which aims to pre- cisely alter specific facts in the memory of LLMs 20 40 60 80 100 Logical Implications Contextual Robustness Traditional KE metrics SAKE ROME ActAdd Figure 1: Summary of the empirical results obtained with SAKE (our method) compared to a weight editing method (ROME) and an activation steering method (Ac- tAdd) for GPT2-XL. through a list of edits (see Wang et al. (2024a) for a survey). However, these methods have been shown to suffer from several limitations: (1) One well- known challenge is that edited LLMs often struggle to generalize their newly acquired knowledge to various types of logical implications (Cohen et al., 2024). (2) Edited LLMs are often not robust to cer- tain rephrasing of the prompts, including those that could realistically arise in a conversation, such as long, noisy prompts or prompts raising doubts on the edited knowledge (Ma et al., 2024). (3) Finally, they generally lack flexibility in revising or remov- ing prior edits. Approaches that modify model weights, such as ROME (Meng et al., 2022a) and MEMIT (Meng et al., 2022b), or rely', 'on external memory in the form of auxiliary networks (Mitchell et al., 2021, 2022), do not inherently support effi- cient revision or removal of prior edits, thus making continuous updates challenging. In this paper, we argue that these limitations come from the design of most KE methods. Most approaches indeed aim to alter the behavior based on a single input prompt, therefore leading to over- fitting and poor generalization properties. After providing background and discussing this issue 1 arXiv:2503.01751v1 [cs.AI] 3 Mar 2025 in Section 2, we propose, to address it, a novel fact-editing framework, called Steering Activations for Knowledge Editing (SAKE). Described in Sec- tion 3, SAKE is based on activation steering and is intended to provide greater flexibility, robustness, and control over knowledge modifications. Unlike traditional KE methods, our approach optimizes the LLM behavior over distributions of text, rather than individual prompts, allowing for more generaliz- able and consistent edits. Our experimental results, described in Sec. 4 and summarized in Figure 1, demonstrate that our proposed method outperforms existing KE approaches in terms of generalization to logical implications, contextual robustness, as well as traditional KE metrics, hence showcasing its capability to perform more robust edits overall. 2 Background 2.1 Knowledge Editing Knowledge Editing (see Wang et al. (2024a) for a survey) is the task of modifying the knowledge stored in LLMs. Given a language model f, an edit is generally defined by a source tuple (s, r, o) (s being the subject, r the relation, and o an old object), and a target tuple (s, r, o∗), with o∗a new object. Concretely, the object o is to be returned when querying the model with (s, r) in the form of natural language (the prompt p): the goal of model editing is thus to define an edited model f∗that outputs o∗given the prompt p, an objective gener- ally defined as \"edit success\" or \"accuracy\". Be- sides accuracy, two other objectives are generally associated to the task of knowledge editing (Meng et al., 2022a; Wang et al., 2024a): the ability of the model to generate o∗given paraphrases p′ of p (generality), and how well the initial behavior of f is preserved for unrelated prompts (specificity). Traditional methods for KE Existing knowl- edge editing (KE) techniques employ a range of strategies. Methods based on targeted modifica- tions of the model’s weights, such as ROME (Meng et al., 2022a) and MEMIT (Meng et al., 2022b) offer the advantage of preserving the original in- ference procedure. However, the knowledge lo- calization assumption they rely on has been the topic of criticism (Hase et al., 2024), as well as their tendency to overfit the input prompt (Zhang et al., 2024). Instead of targetting a specific local- ization, the change in parameters for a given edit are predicted using a hypernetwork in the case of MEND (Mitchell et al., 2021). Other methods rely on external memory units. This is the case of GRACE (Hartvigsen et al., 2024), which uses a memorized codebook to map relevant activations to values that increase the likelihood of the desired output. Similarly,', 'SERAC (Mitchell et al., 2022), passes an input that is to be edited to an external fine-tuned model. Unfortunately, using additional models for memory (and edit scope de- tection in the case of SERAC) is expected to bring additional training overhead, as well as longer in- ference time. Finally, in-context strategies such as IKE (Zheng et al., 2023), modify the model’s behavior temporar- ily during inference by adding additional context in the form of instructions and examples. Although performing well across traditional KE benchmarks, in-context strategies have been shown to struggle in more realistic scenarios (Ma et al., 2024), and are generally expected to suffer from in-context learning (ICL) limitations in terms of generaliza- tion (Mosbach et al., 2023). 2.2 Three Limitations of Existing Methods In this section, we identify three main limitations, common to all aforementioned KE methods, that we seek to address in this paper. Logical implications One implicit, but crucial, objective of knowledge editing is that altering a fact in a model should affect all knowledge directly con- nected to this fact as well. As a result, it is expected that answers to questions on logical implications deriving from the edit should reflect this change as well. These could include, given e.g. an edit performed to update the name of the US president, the composition of multiple relations (e.g. \"the son of the US president\") or subject aliasing (\"the head of state in the US\"). Yet, several works (Ma et al., 2023; Cohen et al., 2024; Li et al., 2024c) have pointed how edited models with existing ap- proaches often fail to generalize their updates to their respective logical implications. In particular, following the categorization of logical implications proposed by Cohen et al. (2024), edited models have been shown to struggle with prompts arising from the composition of two relations (Composi- tionality I and II), and to a lesser extent even from just using aliases of the subject (Subject Aliasing). Moreover, the authors have found that edited mod- els often struggle with prompts with the same sub- ject but a different relation than those in the list of edits, deviating from the original output when it is 2 actually not requested (Relation Specificity). Contextual robustness Besides, the edits per- formed with existing methods have been shown to lack contextual robustness. Ma et al. (2024) thus observe how, in a realistic conversational setting, it is quite easy to make the edited model doubt its newly acquired knowledge, and even to revert it to the pre-edit behavior. Additionally, they have found that edited model struggle with long or noisy contexts, and in situations with prompts raising doubts. Similarly to logical implications, this lack of contextual robustness is problematic as knowl- edge edits are generally intended to hold across diverse situations, e.g. to patch the behavior of a customer-facing chatbot with updated information. Flexible editing mechanism On a different note, we argue that another limitation of existing meth- ods is their lack of flexibility in adding, remov- ing, or altering edits. As knowledge needs to be continuously updated, the ability to update', 'the in- formation stored in a flexible way is crucial. Yet, as multiple edits are being performed simultane- ously, methods relying on direct intervention on the model weights such as ROME (Meng et al., 2022a) and MEMIT (Meng et al., 2022b), and approaches relying on the training of an external memory net- work such as MEND (Mitchell et al., 2021) and SERAC (Mitchell et al., 2022) are unable to simply undo a specific edit. Worse, performing the inverse edit (s, r, o∗→o) to restore the previously lost knowledge has been shown not only to fail in bring- ing the model back to its original form, but also severely hurt the model’s overall performance (Li et al., 2024c; Hu et al., 2024). Since one of the main advantages of knowledge editing over tradi- tional model fine-tuning is the ability to preserve the original model, its limitations in this regard present a significant challenge. 3 Proposition To overcome the three limitations discussed in the previous section, we introduce in this section a new knowledge editing framework. After formal- izing a new objective in Sec. 3.1, we introduce in Sec. 3.2 Steering Activations for Knowledge Editing (SAKE), our approach designed to tackle the issues identified. 3.1 Knowledge Editing as a Distribution Mapping Problem One interpretation for the inability of existing KE methods to generalize well to related inputs (other than simple paraphrases) is that the knowledge to edit is generally represented (and thus passed in the model) as an isolated prompt. This results in a discrepancy between how humans perceive a fact, composed of high-level concepts associated the subject s, the relation r, and the object o, and what is actually passed to the model (a prompt). As a result, the edit may fail to generalize to mere reformulations of the sentence, let alone some log- ical implications. To address this issue, we pro- pose to define the scope of an edit e to include these notions. Following the notations from Wang et al. (2024a), we thus introduce Xe ⊂X as the in-scope input space, Ye ⊂Y as the original out- put space and Y∗e ⊂Y as the target output space. Concretely, Xe covers all the inputs which output should be affected by the edit e. As e is a piece of factual knowledge, these include paraphrases of the prompt, but also any logical implication, or contex- tual knowledge. The objective of a single edit e is then defined by the following robust optimization problem: min f∗∈FEx,y∗∈Xe,Y∗eL(f∗(x), y∗) s.t. f∗(x) = f(x) ∀x ∈X \\\\ Xe, (1) where f∗is the edited model, y∗is the new desired output (note: not necessarily o∗), L a loss assessing the success of the edit by measuring the difference between the edited model’s and the desired output; and F is the set of all possible edited models. Con- sidering facts are interconnected by a plethora of possible logical implications, it is clear that Xe is quite large, especially when compared to the mere prompt (s, r). This underlines the importance to account for the whole distributions of Xe and Ye', 'to perform more robust edits. To approximate the set Xe, we aim to generate a set of inputs that are affected by the edit e (i.e. not just (s, r, o) or its paraphrases). It is clear now that our method cannot simply be based on mapping o →o∗, because the completions of the inputs in Xe are not limited to the original objects of the edit. Thus, we need to find a mapping from a dis- tribution of obsolete knowledge connected to the fact (s, r, o), which is exactly Ye, to a new one revolving around (s, r, o∗), essentially Y∗e. This mapping should be applied whenever a new input 3 1. Distribution modeling Model: until last layer 2. Distribution mapping Model: last layer Agentic or Expert-based 3. Scope detector Output training If in-scope Collect activations If out of scope / London is the capital of the UK à France London is the main city of … London is the main city of France Edit input New sentence inference Figure 2: Overview of SAKE, illustrating our method’s behavior both at training (orange) and test (green) times. at inference time belongs to Xe. As a result, we define our edited model to be f∗:= W(m(T(x))), where W is the linear modeling head of f = W ◦T (T standing for transformer) and m is a function that maps the activations in the last layer hs from a source distribution Se (describing the obsolete knowledge) to ht in the target distribution Te (up- dated knowledge) . With this new viewpoint, equation 1 thus can be reformulated as: min m:Rd→RdEhs,ht∈Se,TeL′(m(hs), ht) s.t. m(h) = h ∀h ∈Rd \\\\ Se, (2) where L′ is an appropriate loss function comparing the transformed layer to the target layer and d the dimensionality of the activation space of f. In the next subsections we accurately describe how we collect the activations and how we learn the optimal mapping m, leading to the complete formulation of the knowledge editing method we propose. 3.2 SAKE: Steering Activations for Knowledge Editing To solve the problem described in Equation 2, we introduce SAKE, which relies on activation steer- ing to perform robust knowledge editing. SAKE relies on three components, which can be visu- alized as grey blocks in Figure 2, and each de- scribed in the following subsections. First, we propose to directly model Ye and Y∗e in the activa- tion space (Sec. 3.2.1, number (1) in Fig. 2); then, we map these distributions using optimal transport (Sec. 3.2.2, number (2)). For inference, we im- plement a scope detection mechanism to target a potentially relevant edit when an input x ∈Xe is passed to the model (Sec. 3.2.3, number (3)). 3.2.1 Modeling Source and Target Distributions To model Xe, as well as, indirectly, Ye and Y∗e, we need sentences in natural language Pe := {pe i}i≤n that are representative of the in-scope inputs that the edit e should generalize to. This thus allows us to include paraphrases and logical implications in these distributions, but also can be adapted dif- ferently to', 'fit specific contexts, such as question answering, text completion, or classification for in- stance. We identify two strategies for modeling Xe, detailed below. Agentic generation: A natural way to generate these distributions is to rely on a trained LLM such as GPT-4, prompted with instructions to paraphrase and derive logical implications of the base edit. Pre- vious works have shown the efficiency of generat- ing paraphrase and specificity prompts for knowl- edge editing (Zhang et al., 2024; Gangadhar and Stratos, 2024). In this work, we extend this to logi- cal implication prompts. Examples of instructions are given in Appendix A.1. Expert-based generation: As the distributions are in the input space, the sentences can be di- rectly generated by human users. In particular when the number of edits is low, it thus allows domain experts to directly define specify the fine- grained behaviors that are expected by the model after editing. This is especially interesting in ap- plications where naive text generation would be insufficient (Mayring, 2025). Since these sentences will also be used to cover Ye and Y∗e with Se and Te respectively, pi should be meant to be completed immediately with either y ∈Ye or y∗∈Y∗e, e.g. \"The US president is\", or \"The son of the US president is\". To collect the source activations Se, we pass pi through f and save the activation at the layer and token of choice. To collect the target activations Te, we need to first build ˜pi = (c, pi), where c is some context that ensures that the output of the unedited model when prompted with ˜pi would belong to Y∗e and not Ye. An example of ˜pi for paraphrases could be: Do not mention o. Repeat this sentence: pi + o∗. pi. Refer to Appendix A.2 for more examples (including those for logical implications). 3.2.2 Mapping and Continuing the Generation Once the distributions Se and Te are collected, we propose to solve Equation 2 using Optimal Trans- 4 port theory (see e.g. Santambrogio (2015)). Al- ready considered for activation steering in the field of NLP to generate linear counterfactuals (Singh et al., 2024; Li et al., 2024b), representation align- ment (Alqahtani et al., 2021), or more generally steer behavior (Rodriguez et al., 2024), optimal transport aims, given two distributions S (source) and T (target), at finding a mapping function m : S →T minimizing some transportation cost, measured traditionally using the Earth Mover’s Dis- tance (EMD) (Kantorovich, 1960). In particular, and for the sake of simplicity, we focus on linear op- timal transport mappings1. That is to say, noting h the last hidden state of the last token of an instance from S, we define the mapping as m : h →Ah+b, where: A = Σ−1/2 s \\x10 Σ1/2 s ΣtΣ1/2 s \\x111/2 Σ−1/2 s , b = µt −Aµs, where µs, µt, Σs, Σt are the empirical means and covariances of the source and target distribu- tions. This mapping is a closed-form solution to the EMD optimal transport problem for normal dis- tributions (Knott and Smith, 1984). The mapping m matches both', 'the mean and covariances of the two empirical distributions, thus eliminating the so called bias-by-neighbors (Gonen and Goldberg, 2019), i.e. members of the same class clustering together after the transformation. During inference, after learning the mapping, when a new prompt x belonging to the distribution from the distribution Xe is passed to the model, the activation of its last hidden state for the final token h is thus collected and replaced with its mapped representation m(h). The generation then contin- ues, leading to a final output W(m(h)). 3.2.3 Assessing Edit Scope The final component of SAKE (numbered 3 in Fig. 2) is used at inference to determine whether a new input refers to knowledge within the scope of a performed edit Xe. If the input is determined to belong to Xe, its activations are collected and passed to the mapping described in the previous section. Otherwise, no intervention is performed, allowing the model to produce its pre-edit output. To do so, we consider several strategies, all having their pros and cons: 1we use the implementation of the PythonOT library (Fla- mary et al., 2021) Figure 3: Performance of SAKE along Accuracy, Gen- erality and Specificity for the first 150 edits of the Coun- terfact dataset depending on the value chosen for ϵ. A larger value for ϵ implies that more prompts are going to be mapped, increasing the Generality score (resp. de- creasing the Specificity score) when they are paraphrase (resp. unrelated) prompts. Choice of the representation: A first intuitive possibility is to rely on the activations hs computed by the model. However, other representations could in theory be considered, e.g. obtained using a pre- trained embedding model. Criterion: To assess whether a new representa- tion h belongs to the source distribution, we rely on a simple threshold ϵ > 0 on the distance to the distribution center: x ∈Xe ⇐⇒||h−P i hs i|| < ϵ, with ||.|| a distance function (e.g. Euclidean). Al- though other, possibly better performing strategies could be envisaged such as training a dedicated classifier (cf. Mitchell et al. (2022), we choose to rely on a simple approach for its computational efficiency. Designing an accurate scope detection mecha- nism is crucial for ensuring the efficiency of SAKE. Mapping sentences that do not belong to the source distribution could indeed lead to unpredictable re- sults. On the contrary, failure to detect an in-scope sentence would result in the mapping underper- forming. This describes a tradeoff between how general and how specific the mapping is, which we control in practice by adjusting the value of ϵ. This tradeoff, previously discussed by Meng et al. (2022b), can be visualized in Figure 3 for the Coun- terfact dataset using prompt embeddings and the Euclidean distance. Finally, this scope detection mechanism also gives SAKE flexibility in adding or removing edits (Limitation 3 of Sec. 2.2). Indeed, as edits are implemented through independent map- pings, adding (resp. removing) an edit has limited effects on other edits. 5 4 Experiments To assess the efficiency of SAKE, we conduct the following experiments. First, we assess the', 'ability of SAKE to overcome some of the limitations of existing methods discussed in Section 2.2 (Sec.4.2). Then, we evaluate how well SAKE performs ac- cording to traditional Knowledge Editing metrics (Sec.4.3). An aggregation of the results in the form for a spider chart is provided in Figure 1. Finally, we present a series of ablation studies to provide a clearer understanding of how the different compo- nents of SAKE contribute to its efficacy (Sec. 4.4). 4.1 Models and Competitors We conduct our experiments on two widely-used language models: GPT2-XL (1.5B parameters) (Radford et al., 2019) and Llama 2-7b (Touvron et al., 2023). We compare our approach against several knowledge editing methods. Specifically, we evaluate three weight editing methods: ROME2 (Meng et al., 2022a), MEMIT (Meng et al., 2022b), and to test logical implications, an adaptation of MEMIT, which we call CompMEMIT designed to be more robust to logical implication (see Sec. 4.2.1 for details); and a modification of ActAdd (Turner et al., 2023), which involves steering activations by simply adding a difference vector between a source and a target prompts. For all experiments, these competitors and base- lines perform one edit at a time, with the model being reset between each edit, except for MEMIT which applies all the edits simultaneously. Details on the experimental protocol and the compared methods are provided in Appendix B. 4.2 Robust Edits with SAKE We first aim to assess the efficiency of SAKE in performing robust edits, specifically evaluating ro- bustness to logical implications and contextual ro- bustness. 4.2.1 Logical Implications We first test SAKE on the Popular dataset from Co- hen et al. (2024), containing 885 edits with a vary- ing number of logical implications each. This task evaluates the ability of editing methods to general- ize to the logical implications of an edit. For each edit, we consider the following metrics: Subject Aliasing (SA), which evaluates the model’s ability 2We use the implementations from the EasyEdit (Wang et al., 2023) library, available under the MIT license, for ROME and MEMIT. Model Method CI CII SA RS GPT2-XL ROME 38.62 16.67 51.96 39.43 MEMIT 2.47 1.95 7.17 3.75 CompMEMIT 20.69 0.00 10.10 14.71 ActAdd 26.63 29.17 42.12 50.68 SAKE (ours) 50.00 33.33 54.59 58.39 LLaMA 2-7b ROME 27.51 8.28 47.72 29.90 MEMIT 5.80 9.28 42.43 24.52 CompMEMIT 17.21 7.89 8.45 48.83 ActAdd 9.57 18.12 47.69 59.40 SAKE 44.32 27.63 53.34 56.93 Table 1: Comparison of metrics (CI, CII, SA, RS) for different methods across two models on the Popular dataset. to generalize over synonyms of the subject s; Com- positionality I (CI) and Compositionality II (CII), for multi-hop reasoning; and Relation Specificity (RS), which measures the logical locality of an edit, i.e. verifying that the model’s output remains un- changed when prompted with inputs containing the same subject but a different relation from that in the original edit. RS is a particularly relevant metric, as certain KE methods tend to overfit to the sub- ject (Zhang et al., 2024). More precise definitions of these metrics can be found in Appendix B.1. Besides the aforementioned', 'baselines, we design another competitor specifically for this experiment. Our objective is to evaluate if our data augmenta- tion strategy described in Section 3.2.1 could also be leveraged to increase the performance of other KE methods. For this purpose, we design Comp- MEMIT, which leverages MEMIT in order to per- form edits that are robust to logical implications. As this method allows for multiple, simultaneous edits, we use the edit prompt and 10 logical im- plications prompts generated for SAKE as inputs. Since these prompts all refer to similar knowledge, considering them as simultaneous edits is expected to improve the robustness of the edits while pre- serving the model’s overall behavior. The results can be found in Table 1. We observe that, for the two models, SAKE performs better than the weight editing methods and ActAdd along all the dimensions considered. In particular, Comp- MEMIT performs worse than ROME across all di- mensions, suggesting that optimizing over multiple logical implications prompts for the same subject actually negatively impacts the model. On the other hand, while the results of SAKE remain well bel- low 100%, which may partly be attributed to some inconsistencies we identified in the dataset, they 6 London is the capital of… …France ??? No, It can’t be, This contradicts my understanding. It is pretty clear that the answer to ’ London is the capital of’ is something else. Rethink and give the correct answer: London is the capital of …the UK Model (after ROME edit) User User Model (after ROME edit) London is the capital of… …France ??? No, It can’t be, This contradicts my understanding. It is pretty clear that the answer to ’ London is the capital of’ is something else. Rethink and give the correct answer: London is the capital of …France Model (after SAKE edit) User User Model (after SAKE edit) Figure 4: Idea behind the \"Contextual Robustness\" ex- periment, using the Raising doubt (DI) experimental protocol from Ma et al. (2024). Model Method DI DII GPT2-XL ROME 33.33 14.00 ActAdd 82.00 80.67 ICL 4.00 3.33 SAKE (ours) 98.67 98.67 LLaMA 2-7b ROME 1.33 23.33 ActAdd 82.67 98.00 ICL 0.00 4.00 SAKE (ours) 92.00 98.67 Table 2: Comparison of robustness to doubtful prompts of SAKE with ROME and in-context editing. still suggest that the method successfully improves generalization to logical implications. 4.2.2 Contextual Robustness In this experiment, we address the second limita- tion of KE methods discussed in Section 2.2 and evaluate SAKE’s ability to retain edited knowledge in more challenging contexts. Following Ma et al. (2024), we assess the model’s robustness to doubt- ful inputs, as represented in Figure 4 (for the spe- cific prompts, refer to B.3). In addition to ROME and ActAdd, we include an in-context baseline (ICL), built, like in Cohen et al. (2024), by ap- pending Imagine that and the edit before the test prompts). Although previous work suggest that in- context learning strategies may achieve satisfying results for Knowledge Editing (Cohen et al., 2024), complex contexts are expected to be challenging. All the results are reported in Table 2.', 'In this con- text, DI refers to a prompt that raises doubts about the new object and is fairly repetitive (often caus- ing LLMs to repeat the input), while DII involves a prompt that explicitly suggests the correct an- swer is actually the old object. The scores reported in the tables represent the frequency with which the model outputs the new object under greedy de- coding, computed over the first 150 edits from the Model Method Acc Gen Spec GPT2-XL ROME 99.55 73.70 82.67 MEMIT 60.00 36.60 67.21 ActAdd 85.00 29.78 82.75 SAKE (ours) 97.00 84.85 84.52 LLaMA 2-7b ROME 99.95 68.20 93.48 MEMIT 74.40 55.13 74.37 ActAdd 90.10 33.65 81.45 SAKE (ours) 97.70 82.03 85.59 Table 3: Comparison of metrics (Accuracy, Generality, Specificity) for different methods across two models on the Counterfact dataset. Counterfact dataset. SAKE demonstrates superior robustness compared to the considered baseline methods ROME, ActAdd and ICL. This underlines in particular the main weakness of the in-context learning baseline: it is (predictably) vulnerable to noise or explicit doubt-raising inputs. SAKE, on the other hand, is particularly effective. 4.3 Traditional Editing Evaluation Finally, we evaluate in this experiment how it per- forms on traditional KE evaluation metrics. We use the Counterfact dataset (Meng et al., 2022a), a commonly used dataset in the KE literature, and calculate the typical KE metrics: accuracy, gen- erality and specificity. We report in Table 3 the scores obtained over the 2000 first edits. On aver- age, SAKE achieves comparable results to ROME, and outperforms other methods. The most notable improvement is observed on the Generality metric, which may be explained by SAKE’s distribution modeling step, allowing it to account for multiple paraphrase prompts. 4.4 Ablation Studies We now propose additional analyses to get insights into how SAKE effectively edits factual knowledge. We structure the two proposed experiments around the main components of SAKE: in-scope distribu- tion modeling, and optimal transport mapping. 4.4.1 How does SAKE scale with training prompts? The generation of the in-scope prompts (cf. Sec. 3.2.1), whether agentic or human-based, repre- sents the primary computational cost of performing an edit with SAKE. Hence, an interesting ques- tion is how the SAKE’s performance changes as the number of prompts used to collect source and target activations varies, and how many prompts are actually required to achieve satisfactory results. 7 Figure 5: Performance of SAKE along Accuracy, Gen- erality and Specificity for the first 150 edits of the Coun- terfact dataset depending on the number of training prompts used to model source and target distributions. Model Method Acc Gen GPT2-XL Uniform steering 85.05 35.45 SAKE 97.00 84.85 LLaMA 2-7b Uniform steering 91.05 40.73 SAKE 97.70 82.03 Table 4: Comparison between SAKE and the Uniform Steering baseline on the Counterfact dataset. Figure 5 shows the evolution of traditional KE met- rics on 150 edits from the Counterfact dataset as a function of the number of prompts n generated in the Distribution Modeling step. We observe that ac- curacy and paraphrase performance improve as the number of paraphrases increases, since the method becomes more robust to prompts', 'rephrasing. No- tably, the specificity score does not decrease with more training prompts, as this number has little impact on the scope detection mechanism. Only 50 paraphrase prompts are thus required to achieve 0.92 in Accuracy and 0.84 in Generality. 4.4.2 What does Optimal Transport bring? Model Method CI CII SA GPT2-XL Uniform steering 47.85 32.14 52.74 SAKE 50.00 33.33 54.59 LLaMA 2-7b Uniform steering 20.79 20.62 50.23 SAKE 44.32 27.63 53.34 Table 5: Comparison between SAKE and the Uniform Steering baseline on the Popular dataset. Another key component of SAKE is learning a mapping between the source and target distribu- tions (cf. Sec. 3.2.2). Prior works focusing on activation steering to alter the behavior of language models for other objectives than knowledge editing mainly rely on simpler approaches, such as comput- ing the difference vectors between the distribution means (Subramani et al., 2022; Ilharco et al., 2023; Stolfo et al., 2024; Li et al., 2024a; Arditi et al., 2024). Unlike these steering methods, based on a constant vector between distributions, using an optimal transport mapping is expected to better preserve the mapped distributions. In particular, rather than matching only the distribution means, the considered linear transport mapping preserves the whole covariance matrix of the target distribu- tion. We therefore propose to empirically evaluate the benefit of this approach for knowledge editing by introducing a baseline method, referred to as \"Uniform steering\", which steers representations h from the source representation to h + (µt −µs). The results are shown in Table 4 for the Counterfact dataset, and Table 5 for Popular. The specificity and RS metrics are not displayed, as it is primarily defined by the scope detection mechanism, which is identical for both approaches. We observe that this ability to better preserve distributions indeed trans- lates into improved KE performances for SAKE, particularly with regards to generalization to para- phrases (Generality) and Compositionality I. 5 Conclusion In this paper, we explored how activation steer- ing can be leveraged to edit factual knowledge stored in Large Language Models (LLMs). Our findings suggest that relying only on a single input prompt in insufficient to capture the complexity of the knowledge scope affected by edits. We also propose SAKE, which leverages Optimal Trans- port to better capture this distribution and perform more robust and flexible edits compared to existing methods. Future works include conducting exper- iments in specialized contexts, such as Q&A, as SAKE’s distribution modeling scope is expected to facilitate adaptation to such contexts. Addition- ally, we aim to explore strategies for improving the synthetic generation of the source and target distributions, e.g. through automatic differentiation via text-based iterative agent collaborations. 6 Limitations The main limitation that we identify for our work is that it relies heavily on the assumption that the in-scope distributions can be accurately modeled. 8 Although the results displayed in the paper are en- couraging, it remains unclear whether our empir- ical distributions are good approximations of the theoretical source and target regions, and therefore captures all learnable implications from source to target. In particular, reverse relations, discussed for', 'instance by Yao et al. (2023), are a type of logical implications that is not addressed, and cannot be easily integrated into our method. References Sawsan Alqahtani, Garima Lalwani, Yi Zhang, Salva- tore Romeo, and Saab Mansour. 2021. Using optimal transport as alignment objective for fine-tuning mul- tilingual contextualized embeddings. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3904–3919. Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Panickssery, Wes Gurnee, and Neel Nanda. 2024. Refusal in language models is mediated by a single direction. arXiv preprint arXiv:2406.11717. Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, and Min- joon Seo. 2024. How do large language models acquire factual knowledge during pretraining? In Proceedings of the 38th Conference on Neural Infor- mation Processing Systems (NeurIPS). Curran Asso- ciates, Inc. Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, and Mor Geva. 2024. Evaluating the ripple effects of knowledge editing in language models. Transac- tions of the Association for Computational Linguis- tics, 12:283–298. Rémi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar Z. Alaya, Aurélie Boisbunon, Stanislas Chambon, Laetitia Chapel, Adrien Corenflos, Kilian Fatras, Nemo Fournier, Léo Gautheron, Nathalie T.H. Gayraud, Hicham Janati, Alain Rakotomamonjy, Iev- gen Redko, Antoine Rolet, Antony Schutz, Vivien Seguy, Danica J. Sutherland, Romain Tavenard, Alexander Tong, and Titouan Vayer. 2021. Pot: Python optimal transport. Journal of Machine Learn- ing Research, 22(78):1–8. Govind Krishnan Gangadhar and Karl Stratos. 2024. Model editing by standard fine-tuning. In Findings of the Association for Computational Linguistics ACL 2024, pages 5907–5913. Hila Gonen and Yoav Goldberg. 2019. Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them. arXiv preprint arXiv:1903.03862. Tom Hartvigsen, Swami Sankaranarayanan, Hamid Palangi, Yoon Kim, and Marzyeh Ghassemi. 2024. Aging with grace: Lifelong model editing with dis- crete key-value adaptors. Advances in Neural Infor- mation Processing Systems, 36. Peter Hase, Mohit Bansal, Been Kim, and Asma Ghan- deharioun. 2024. Does localization inform editing? surprising differences in causality-based localization vs. knowledge editing in language models. Advances in Neural Information Processing Systems, 36. Chenhui Hu, Pengfei Cao, Yubo Chen, Kang Liu, and Jun Zhao. 2024. Wilke: Wise-layer knowledge ed- itor for lifelong knowledge editing. arXiv preprint arXiv:2402.10987. Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adap- tation of large language models. arXiv preprint arXiv:2106.09685. Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Worts- man, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi. 2023. Editing models with task arithmetic. In The Eleventh International Conference on Learn- ing Representations. Zhengbao Jiang, Frank F Xu, Jun Araki, and Graham Neubig. 2020. How can we know what language models know? Transactions of the Association for Computational Linguistics, 8:423–438. Leonid V Kantorovich. 1960. Mathematical methods of organizing and planning production. Management science, 6(4):366–422. Martin Knott and Cyril S Smith. 1984. On the optimal mapping of distributions. Journal of Optimization Theory and Applications, 43:39–49. Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, and Martin Wattenberg. 2024a. Inference- time intervention: Eliciting truthful answers from a language model. Advances', 'in Neural Information Processing Systems, 36. Xuhong Li, Jiamin Chen, Yekun Chai, and Haoyi Xiong. 2024b. Gilot: Interpreting generative language mod- els via optimal transport. In Forty-first International Conference on Machine Learning. Zhoubo Li, Ningyu Zhang, Yunzhi Yao, Mengru Wang, Xi Chen, and Huajun Chen. 2024c. Unveiling the pit- falls of knowledge editing for large language models. In The Twelfth International Conference on Learning Representations. Jun-Yu Ma, Jia-Chen Gu, Zhen-Hua Ling, Quan Liu, and Cong Liu. 2023. Untying the reversal curse via bidirectional language model editing. arXiv preprint arXiv:2310.10322. Xinbei Ma, Tianjie Ju, Jiyang Qiu, Zhuosheng Zhang, Hai Zhao, Lifeng Liu, and Yulong Wang. 2024. On the robustness of editing large language models. In Proceedings of the 2024 Conference on Empirical 9 Methods in Natural Language Processing, pages 16197–16216. Philipp Mayring. 2025. Qualitative content analysis with chatgpt: Pitfalls, rough approximations and gross errors. a field report. Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. 2022a. Locating and editing factual as- sociations in gpt. Advances in Neural Information Processing Systems, 35:17359–17372. Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau. 2022b. Mass- editing memory in a transformer. The Eleventh Inter- national Conference on Learning Representations. Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher D Manning. 2021. Fast model editing at scale. International Conference on Learn- ing Representations. Eric Mitchell, Charles Lin, Antoine Bosselut, Christo- pher D Manning, and Chelsea Finn. 2022. Memory- based model editing at scale. In International Con- ference on Machine Learning, pages 15817–15831. PMLR. Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Di- etrich Klakow, and Yanai Elazar. 2023. Few-shot fine-tuning vs. in-context learning: A fair compari- son and evaluation. In The 61st Annual Meeting Of The Association For Computational Linguistics. Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. Language models as knowl- edge bases? In Proceedings of the 2019 Confer- ence on Empirical Methods in Natural Language Pro- cessing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463–2473. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9. Rafael Rafailov, Archit Sharma, Eric Mitchell, Christo- pher D Manning, Stefano Ermon, and Chelsea Finn. 2024. Direct preference optimization: Your language model is secretly a reward model. Advances in Neu- ral Information Processing Systems, 36. Pau Rodriguez, Arno Blaas, Michal Klein, Luca Zap- pella, Nicholas Apostoloff, Marco Cuturi, and Xavier Suau. 2024. Controlling language and diffusion models by transporting activations. arXiv preprint arXiv:2410.23054. Filippo Santambrogio. 2015. Optimal Transport for Ap- plied Mathematicians: Calculus of Variations, PDEs, and Modeling, volume 87. Birkhäuser. Shashwat Singh, Shauli Ravfogel, Jonathan Herzig, Roee Aharoni, Ryan Cotterell, and Ponnurangam Kumaraguru. 2024. Representation surgery: theory and practice of affine steering. In Proceedings of the 41st International Conference on Machine Learning, pages 45663–45680. Alessandro Stolfo, Vidhisha Balachandran, Safoora Yousefi, Eric Horvitz, and Besmira Nushi. 2024. Improving instruction-following in language mod- els through activation steering. arXiv preprint arXiv:2410.12877. Nishant Subramani, Nivedita Suresh, and Matthew E Peters. 2022. Extracting latent steering', 'vectors from pretrained language models. In Findings of the As- sociation for Computational Linguistics: ACL 2022, pages 566–581. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al- bert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open founda- tion and fine-tuned chat models. arXiv preprint arXiv:2307.09288. Alexander Matt Turner, Lisa Thiergart, Gavin Leech, David Udell, Juan J Vazquez, Ulisse Mini, and Monte MacDiarmid. 2023. Activation addition: Steering language models without optimization. arXiv e- prints, pages arXiv–2308. Peng Wang, Ningyu Zhang, Xin Xie, Yunzhi Yao, Bozhong Tian, Mengru Wang, Zekun Xi, Siyuan Cheng, Kangwei Liu, Guozhou Zheng, et al. 2023. Easyedit: An easy-to-use knowledge editing frame- work for large language models. arXiv preprint arXiv:2308.07269. Song Wang, Yaochen Zhu, Haochen Liu, Zaiyi Zheng, Chen Chen, and Jundong Li. 2024a. Knowledge editing for large language models: A survey. ACM Computing Surveys. Weixuan Wang, Barry Haddow, Alexandra Birch, and Wei Peng. 2024b. Assessing factual reliability of large language model knowledge. In Proceedings of the 2024 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Pa- pers), NAACL 2024, Mexico City, Mexico, June 16-21, 2024, pages 805–819. Association for Computational Linguistics. Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, and Ningyu Zhang. 2023. Editing large language models: Prob- lems, methods, and opportunities. arXiv preprint arXiv:2305.13172. Mengqi Zhang, Xiaotian Ye, Qiang Liu, Pengjie Ren, Shu Wu, and Zhumin Chen. 2024. Uncovering overfitting in large language model editing. arXiv preprint arXiv:2410.07819. 10 Yu Zhao, Alessio Devoto, Giwon Hong, Xiaotang Du, Aryo Pradipta Gema, Hongru Wang, Kam-Fai Wong, and Pasquale Minervini. 2024. Steering knowledge selection behaviours in llms via sae-based representa- tion engineering. arXiv preprint arXiv:2410.15999. Ce Zheng, Lei Li, Qingxiu Dong, Yuxuan Fan, Zhiyong Wu, Jingjing Xu, and Baobao Chang. 2023. Can we edit factual knowledge by in-context learning? arXiv preprint arXiv:2305.12740. Chen Zhu, Ankit Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli, Daliang Li, Felix Yu, and Sanjiv Kumar. 2020. Modifying memories in transformer models. arXiv preprint arXiv:2012.00363. A Details on SAKE A.1 Prompts to generate approximation of in-scope input space Write 100 sentences with a similar meaning of: ‘p’. Make sure that the sentences are meant to be immediately completed with precisely: o*. Often, this could require ending the sentence with ‘the’, or something like that. Do not use ‘...’ or ‘____’. Return the sentences as a Python list. Do not output anything else. A.2 Prompts to collect source and target activations For source distributions we passed the generated prompts as they were, and also with the following inputs: Repeat this sentence: ‘p_i + o’. p_i For target distributions, we passed: Do not men- tion ‘o’. Repeat this sentence: ‘p_i + o*’. p_i A.3 SAKE Parameters • Threshold: – GPT2-XL and Llama 2-7b, Counterfact: 6.75 (Euclidean distance, on prompt). – GPT2-XL on RippleEdits Popular: 5.5 (Euclidean distance, on prompt). – Llama 2-7b on RippleEdits Popular: 5.3 (Euclidean distance, on prompt). • Linear Optimal Transport regulariza- tion (ot.da.LinearTransport from the PythonOT library): – 0.01 for GPT2-XL', '– 0.5 for Llama 2-7b • Number of prompts: – GPT2-XL and Llama 2-7b, Counterfact: 100 paraphrases of main edit. – GPT2-XL RippleEdits Popular: 100 paraphrases of main edits, 10 logical im- plications augmented with 4 randomly generated neighbor embeddings for each of the 10 activations collected. – Llama 2-7b RippleEdits Popular: 100 paraphrases of main edits, around 50 log- ical implications with no noise added. B Experimental Protocol B.1 Datasets and metrics • Counterfact (Meng et al., 2022a) is a popular benchmark in the field of Knowledge Editing, evaluating accuracy (recalling the exact edit), generality (generalizing to simple paraphrases of the edit) and specificity (not altering the behavior of the model for unrelated inputs). Specificity prompts in the Counterfact dataset are limited to inputs that, when compared with the original edit, have a different subject, but same relation and old object. Counterfact con- tains 21919 edits and we perform our experi- ment on a subset made of the first 2000. • Popular subset of RippleEdits (Cohen et al., 2024). RippleEdits is a benchmark designed to capture various types of ripple effects caused by knowledge editing. We focus on the Popular subset, containing 885 edits where subjects are well known. We perform our eval- uation on the following four metrics: – Compositionality I: prompts containing the same subject but the composition of two relations, one being from the original edit. – Compositionality II: prompts containing the composition of two relations, one be- ing from the relation in the original edit and the other one describing the subject of the original edit (e.g. if the subject is Prince, a relation describing this subject would be The founder of Paisley Park Records). – Subject Aliasing: prompts containing aliases of the subject appearing in the original edit. – Relation Specificity: specificity prompts with the same subject but different rela- tion. 11 B.2 Competitors In the experiments, we use the following competi- tors: • ROME (Meng et al., 2022a): ROME relies on the assumption of knowledge localization, i.e. that facts are stored in very specific parts of the network. To alter facts, ROME first com- putes key-value pairs associated to a specific prompt and desired output in one early-to-mid MLP layer of the transformer. Then, the new fact is inserted by modifying the current MLP layer with a rank-one update. ROME only allows to perform edits one by one. To use ROME, we use the EasyEdit library with de- fault parameters and perform the edits one by one, i.e. after an edit is performed, we eval- uate the performance on the testing prompts, and then we re-instantiate the model to be edited again starting from the original pre- trained version. • MEMIT (Meng et al., 2022b) uses a similar approach to ROME, but extended to multiple edits at once. The key-value pairs are com- puted for a list of edits, and the matrix update is found by considering all edits simultane- ously. Then, optionally, multiple consecutive MLP layers can be modified by so that each layer contributes to an approximately equal portion of the update (based', 'on the assumption that robustness of the editing method would improve if the change in model weights is min- imized). In our experiments, we performed the edit using MEMIT all at once and then evaluated the edited model. • CompMEMIT is a competitor designed by us to see if adding logical implications to the main prompt would make the method more robust. In particular, we use MEMIT to edit the model with the main prompt plus 10 log- ical implications, then we evaluate it on the appropriate prompts, and then we restore the model to its original form before editing and testing it again. • ActAdd (Zhao et al., 2024) is a method origi- nally designed to control models’ outputs (e.g. making them less toxic) by adding a (possibly scaled) steering activation vector at a certain layer. The steering vector is computed by de- signing two contrasting prompts (e.g. a toxic one vs a non-toxic one) and computing the dif- ference in activations when passing them as inputs. In our setup, the contrasting prompts (one pair per edit) are inputs designed so that the model is about to output the old object vs the new object. As ActAdd is initilly designed to steer all inputs, we use our scope detection mechanism to ensure meaningful specificity scores. • ICL is an in-context baseline that we used to assess the effectiveness of in-context tech- niques. The design is quite simple: if p* is the edit prompt (including the new object), we simply place Imagine that p* before the actual testing prompt. B.3 Doubtful prompts (Contextual Robustness experiment) The doubtful prompts used in the Contextual Ro- bustness experiment are taken from (Ma et al., 2024) (see “raising doubts\" metric). Specifically, if p is the prompt and o and o* the old and new object, respectively, we have • DI: p, o* ??? No, It can’t be, This contradicts my understanding. It is pretty clear that the answer to p is something else. Rethink and give the correct answer: • DII: p, o*? Really? But I am pretty sure that The language of Dehkhoda Dictionary is o. Am I right? Yes! you are right. I apologize for any confusion. Reconsider that the answer to ‘ question p?’ should be 12']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-0\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-0\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-1\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-1\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-2\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-2\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-3\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-3\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-4\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-4\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-5\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-5\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-6\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-6\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-7\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-7\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-8\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-8\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-9\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-9\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-10\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-10\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-11\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-11\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-12\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-12\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-13\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-13\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-14\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-14\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2503.01751-15\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2503.01751-15\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete\n",
            "Context:\n",
            "instance by Yao et al. (2023), are a type of logical implications that is not addressed, and cannot be easily integrated into our method. References Sawsan Alqahtani, Garima Lalwani, Yi Zhang, Salva- tore Romeo, and Saab Mansour. 2021. Using optimal transport as alignment objective for fine-tuning mul- tilingual contextualized embeddings. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3904–3919. Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Panickssery, Wes Gurnee, and Neel Nanda. 2024. Refusal in language models is mediated by a single direction. arXiv preprint arXiv:2406.11717. Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, and Min- joon Seo. 2024. How do large language models acquire factual knowledge during pretraining? In Proceedings of the 38th Conference on Neural Infor- mation Processing Systems (NeurIPS). Curran Asso- ciates, Inc. Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, and Mor Geva. 2024. Evaluating the ripple effects of knowledge editing in language models. Transac- tions of the Association for Computational Linguis- tics, 12:283–298. Rémi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar Z. Alaya, Aurélie Boisbunon, Stanislas Chambon, Laetitia Chapel, Adrien Corenflos, Kilian Fatras, Nemo Fournier, Léo Gautheron, Nathalie T.H. Gayraud, Hicham Janati, Alain Rakotomamonjy, Iev- gen Redko, Antoine Rolet, Antony Schutz, Vivien Seguy, Danica J. Sutherland, Romain Tavenard, Alexander Tong, and Titouan Vayer. 2021. Pot: Python optimal transport. Journal of Machine Learn- ing Research, 22(78):1–8. Govind Krishnan Gangadhar and Karl Stratos. 2024. Model editing by standard fine-tuning. In Findings of the Association for Computational Linguistics ACL 2024, pages 5907–5913. Hila Gonen and Yoav Goldberg. 2019. Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them. arXiv preprint arXiv:1903.03862. Tom Hartvigsen, Swami Sankaranarayanan, Hamid Palangi, Yoon Kim, and Marzyeh Ghassemi. 2024. Aging with grace: Lifelong model editing with dis- crete key-value adaptors. Advances in Neural Infor- mation Processing Systems, 36. Peter Hase, Mohit Bansal, Been Kim, and Asma Ghan- deharioun. 2024. Does localization inform editing? surprising differences in causality-based localization vs. knowledge editing in language models. Advances in Neural Information Processing Systems, 36. Chenhui Hu, Pengfei Cao, Yubo Chen, Kang Liu, and Jun Zhao. 2024. Wilke: Wise-layer knowledge ed- itor for lifelong knowledge editing. arXiv preprint arXiv:2402.10987. Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adap- tation of large language models. arXiv preprint arXiv:2106.09685. Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Worts- man, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi. 2023. Editing models with task arithmetic. In The E\n",
            "\n",
            "Question:What does the conclusion of this paper say?\n",
            "Answer: The conclusion of this paper says that context-based knowledge editing is a better way to fine-tune large language models than standard fine-tuning.\n"
          ]
        }
      ]
    }
  ]
}